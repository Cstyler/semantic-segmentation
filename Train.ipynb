{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9t5hJwCVGuVE",
    "outputId": "03059fdd-140d-4628-9feb-5831e570918c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    from google.colab import drive\n",
    "\n",
    "    subprocess.run([\"pip\", \"install\", \"torchmetrics\", \"optuna\"])\n",
    "    base_dir = \"/content/drive/MyDrive/Colab_Notebooks/Crack_Detection\"\n",
    "    drive.mount(\"/content/drive\")\n",
    "    sys.path.append(os.path.join(base_dir, \"semantic-segmentation\"))\n",
    "    LOCAL = False\n",
    "except ImportError:\n",
    "    base_dir = \".\"\n",
    "    LOCAL = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall\n",
    "from torchmetrics.clustering import RandScore\n",
    "\n",
    "from train import (\n",
    "    DataLoader,\n",
    "    ImageMaskTransform,\n",
    "    SegmentationDataset,\n",
    "    UNet,\n",
    "    cross_entropy_weighted,\n",
    "    init_data_loaders,\n",
    "    init_datasets,\n",
    "    tune_hyperparams,\n",
    "    train_fixed_hyperparams,\n",
    ")\n",
    "\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {os.path.join(base_dir, \"runs\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tune_hyperparams(base_dir, LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'min_save_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_fixed_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCAL\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/train.py:336\u001b[0m, in \u001b[0;36mtrain_fixed_hyperparams\u001b[0;34m(base_dir, local)\u001b[0m\n\u001b[1;32m    334\u001b[0m use_cosine_scheduler \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cosine_scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    335\u001b[0m min_lr \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_lr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 336\u001b[0m min_save_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin_save_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    337\u001b[0m early_stop_patience \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stop_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    338\u001b[0m t_0 \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'min_save_epoch'"
     ]
    }
   ],
   "source": [
    "train_fixed_hyperparams(base_dir, LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of studies: 14\n",
      "study-0502-175709\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# study_name = \"study-0506-190624\"\n",
    "study_name = \"study-0502-175711\"\n",
    "# study_name = \"study-0428\"\n",
    "storage = f\"sqlite:///Data/{study_name}/Data/seg-study.db\"\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"Num of studies:\", len(studies))\n",
    "study = studies[-1]\n",
    "print(study.study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"Data/{study_name}/Data/studies/{study.study_name}.pkl\", \"rb\") as f:\n",
    "        study_dict = pickle.load(f)\n",
    "\n",
    "    study = optuna.load_study(\n",
    "        study_name=study.study_name,\n",
    "        storage=storage,\n",
    "        sampler=study_dict[\"sampler\"],\n",
    "        pruner=study_dict[\"pruner\"],\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    study = optuna.load_study(study_name=study.study_name, storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13715654611587524,\n",
       " 47,\n",
       " <optuna.pruners._median.MedianPruner at 0x7437597b1870>,\n",
       " {'flip_prob': 0.042747388239577966,\n",
       "  'rotate_prob': 0.4719902190284881,\n",
       "  'elastic_prob': 0.01567998717280196,\n",
       "  'translate_prob': 0.15377448395168106,\n",
       "  'brightness_prob': 0.138486416623626,\n",
       "  'batch_size': 8,\n",
       "  'dropout_p': 0.5328890961652364,\n",
       "  'vanilla_loss': True,\n",
       "  'use_adam': True,\n",
       "  'lr': 0.00036296166101104416,\n",
       "  'use_cosine_scheduler': False,\n",
       "  'min_lr': 1.0017766083008169e-08,\n",
       "  'lr_patience': 18,\n",
       "  'lr_cooldown': 1,\n",
       "  'lr_factor': 0.06925485872989952})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value, len(study.trials), study.pruner, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14338421821594238,\n",
       " 100,\n",
       " <optuna.pruners._hyperband.HyperbandPruner at 0x7c74eecb5390>,\n",
       " {'flip_prob': 0.04459255293028834,\n",
       "  'rotate_prob': 0.40379419104333913,\n",
       "  'elastic_prob': 0.014062767704262479,\n",
       "  'translate_prob': 0.33608821897374763,\n",
       "  'brightness_prob': 0.23828063471331679,\n",
       "  'batch_size': 9,\n",
       "  'dropout_p': 0.2887745942859943,\n",
       "  'vanilla_loss': True,\n",
       "  'use_adam': True,\n",
       "  'lr': 0.0003909349124991186,\n",
       "  'use_cosine_scheduler': False,\n",
       "  'min_lr': 6.945255506527192e-08,\n",
       "  'lr_patience': 24,\n",
       "  'lr_cooldown': 1,\n",
       "  'lr_factor': 0.2878405900553068})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value, len(study.trials), study.pruner, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in study.trials:\n",
    "    params = trial.params\n",
    "    if not params[\"vanilla_loss\"]:\n",
    "        v = trial.value\n",
    "        if v and v < 0.25:\n",
    "            print(f\"{v:0.3f}\", trial.number, trial.params, trial.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_adam': np.float64(0.3977645095745252),\n",
       " 'vanilla_loss': np.float64(0.1406793931554693),\n",
       " 'elastic_prob': np.float64(0.08746186350862907),\n",
       " 'batch_size': np.float64(0.08671901945241697),\n",
       " 'use_cosine_scheduler': np.float64(0.08402969690245228),\n",
       " 'brightness_prob': np.float64(0.06316926781526236),\n",
       " 'translate_prob': np.float64(0.043377337361138406),\n",
       " 'rotate_prob': np.float64(0.031254978146683376),\n",
       " 'flip_prob': np.float64(0.025227132797285463),\n",
       " 'min_lr': np.float64(0.021256423150298954),\n",
       " 'dropout_p': np.float64(0.0190603781358387)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image_dir, train_images, train_mask_dir, val_images, val_percent) = (\n",
    "    init_datasets(base_dir)\n",
    ")\n",
    "\n",
    "flip_prob = 0.1\n",
    "rotate_prob = 0.1\n",
    "elastic_prob = 0.11\n",
    "translate_prob = 0.1\n",
    "brightness_prob = 0.1\n",
    "batch_size = 1 if LOCAL else 9\n",
    "train_dataloader, val_dataloader = init_data_loaders(\n",
    "    batch_size,\n",
    "    brightness_prob,\n",
    "    elastic_prob,\n",
    "    flip_prob,\n",
    "    rotate_prob,\n",
    "    train_image_dir,\n",
    "    train_images,\n",
    "    train_mask_dir,\n",
    "    translate_prob,\n",
    "    val_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwsxMbNmlhdP"
   },
   "outputs": [],
   "source": [
    "for images, masks in train_dataloader:\n",
    "    image = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "    mask = masks[0].cpu().numpy().squeeze()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(image, cmap=\"gray\")\n",
    "    axs[1].imshow(mask, cmap=\"gray\")\n",
    "    assert image.shape[:2] == (572, 572)\n",
    "    assert mask.shape == (388, 388)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9lGNuk4W7KF",
    "outputId": "bde762f9-2ab3-4d59-ddd8-8d5501cff58a"
   },
   "outputs": [],
   "source": [
    "loss_w0, loss_sigma = 5, 5\n",
    "loss_w1 = 1.0\n",
    "dropout_p = 0.2\n",
    "vanilla_loss = True\n",
    "\n",
    "test_image_dir = os.path.join(base_dir, \"isbi_2012_challenge/test/imgs\")\n",
    "test_mask_dir = os.path.join(base_dir, \"isbi_2012_challenge/test/labels\")\n",
    "\n",
    "test_images = os.listdir(test_image_dir)\n",
    "test_transforms = ImageMaskTransform(train=False)\n",
    "test_dataset = SegmentationDataset(\n",
    "    test_image_dir, test_mask_dir, test_images, transform=test_transforms\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "pretrained_weights_path = \"checkpoints/C1.pth\"\n",
    "model = UNet(dropout_p=dropout_p)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "accuracy_metric_test = BinaryAccuracy().to(device)\n",
    "precision_metric_test = BinaryPrecision().to(device)\n",
    "recall_metric_test = BinaryRecall().to(device)\n",
    "rand_score_metric_test = RandScore().to(device)\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        labels = labels.squeeze(1)\n",
    "        loss = cross_entropy_weighted(\n",
    "            outputs,\n",
    "            labels,\n",
    "            device,\n",
    "            loss_w0,\n",
    "            loss_sigma,\n",
    "            loss_w1,\n",
    "            vanilla=vanilla_loss,\n",
    "        )\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        accuracy_metric_test.update(preds, labels)\n",
    "        recall_metric_test.update(preds, labels)\n",
    "        precision_metric_test.update(preds, labels)\n",
    "        rand_score_metric_test.update(preds.view(-1), labels.view(-1))\n",
    "\n",
    "print(\n",
    "    f\"(Test) Loss: {test_loss / len(test_dataloader):.4f}, \"\n",
    "    f\"Rand error: {1 - rand_score_metric_test.compute():.4f} \"\n",
    "    f\"Pixel Error: {1 - accuracy_metric_test.compute():.4f} \"\n",
    "    f\"Recall: {recall_metric_test.compute():.4f} \"\n",
    "    f\"Precision: {precision_metric_test.compute():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K52mxkXvBKP0",
    "outputId": "8e246a43-f660-4e1c-9c4d-c46504d9093c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        image = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "        mask = labels[0].cpu().numpy().squeeze()\n",
    "\n",
    "        predicted_mask = torch.argmax(outputs[0], dim=0).cpu().numpy()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        axs[0].imshow(image, cmap=\"gray\")\n",
    "        axs[0].set_title(\"Image\")\n",
    "        axs[0].axis(\"off\")\n",
    "\n",
    "        axs[1].imshow(mask, cmap=\"gray\")\n",
    "        axs[1].set_title(\"Ground Truth Mask\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "        axs[2].imshow(predicted_mask, cmap=\"gray\")\n",
    "        axs[2].set_title(\"Predicted Mask\")\n",
    "        axs[2].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "lylunDHWW7KD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "W0, SIGMA = 5, 5\n",
    "for images, labels in train_dataloader:\n",
    "    borders = find_boundaries(labels)\n",
    "    dist = distance_transform_edt(~borders)\n",
    "    w = W0 * np.exp(-2 * dist**2 / SIGMA**2)\n",
    "\n",
    "    labels_bincount = torch.bincount(labels.flatten())\n",
    "    w_class = labels_bincount.sum() / labels_bincount\n",
    "    print(w_class, labels_bincount.sum())\n",
    "\n",
    "    class_map = w_class[labels]\n",
    "    print(class_map)\n",
    "\n",
    "    w_final = class_map.numpy() + w\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(19, 6))\n",
    "    axs[0].imshow(labels.squeeze(), cmap=\"gray\")\n",
    "    axs[1].imshow(~borders.squeeze(), cmap=\"gray\")\n",
    "    axs[2].imshow(w.squeeze(), cmap=\"coolwarm\")\n",
    "    axs[3].imshow(w_final.squeeze(), cmap=\"coolwarm\")\n",
    "    plt.show()\n",
    "    plt.hist(w.flatten(), bins=10)\n",
    "    plt.show()\n",
    "    plt.hist(w_final.flatten(), bins=10)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrfX8NkNW7KF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
