{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9t5hJwCVGuVE",
    "outputId": "03059fdd-140d-4628-9feb-5831e570918c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    from google.colab import drive\n",
    "\n",
    "    subprocess.run([\"pip\", \"install\", \"torchmetrics\", \"optuna\"])\n",
    "    base_dir = \"/content/drive/MyDrive/Colab_Notebooks/Crack_Detection\"\n",
    "    drive.mount(\"/content/drive\")\n",
    "    sys.path.append(os.path.join(base_dir, \"semantic-segmentation\"))\n",
    "    LOCAL = False\n",
    "except ImportError:\n",
    "    base_dir = \".\"\n",
    "    LOCAL = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import find_boundaries\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall\n",
    "from torchmetrics.clustering import RandScore\n",
    "\n",
    "from train import (\n",
    "    DataLoader,\n",
    "    ImageMaskTransform,\n",
    "    SegmentationDataset,\n",
    "    UNet,\n",
    "    cross_entropy_weighted,\n",
    "    init_data_loaders,\n",
    "    init_datasets,\n",
    "    tune_hyperparams,\n",
    "    train_fixed_hyperparams,\n",
    ")\n",
    "\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {os.path.join(base_dir, \"runs\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tune_hyperparams(base_dir, LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss/train: 0.0289, RandError/train: 0.3773, PixelError/train: 0.2523, Recall/train: 1.0000, Precision/train: 0.7477, Loss/val: 0.1128, VanillaLoss/val: 0.1128, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 2/500, Loss/train: 0.0284, RandError/train: 0.3289, PixelError/train: 0.2075, Recall/train: 1.0000, Precision/train: 0.7925, Loss/val: 0.1102, VanillaLoss/val: 0.1102, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 3/500, Loss/train: 0.0278, RandError/train: 0.3447, PixelError/train: 0.2213, Recall/train: 1.0000, Precision/train: 0.7787, Loss/val: 0.1066, VanillaLoss/val: 0.1066, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 4/500, Loss/train: 0.0261, RandError/train: 0.3707, PixelError/train: 0.2457, Recall/train: 1.0000, Precision/train: 0.7543, Loss/val: 0.1018, VanillaLoss/val: 0.1018, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 5/500, Loss/train: 0.0257, RandError/train: 0.3917, PixelError/train: 0.2673, Recall/train: 1.0000, Precision/train: 0.7327, Loss/val: 0.0950, VanillaLoss/val: 0.0950, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 6/500, Loss/train: 0.0257, RandError/train: 0.3832, PixelError/train: 0.2583, Recall/train: 1.0000, Precision/train: 0.7417, Loss/val: 0.0853, VanillaLoss/val: 0.0853, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 7/500, Loss/train: 0.0219, RandError/train: 0.3656, PixelError/train: 0.2408, Recall/train: 1.0000, Precision/train: 0.7592, Loss/val: 0.0781, VanillaLoss/val: 0.0781, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 8/500, Loss/train: 0.0203, RandError/train: 0.3667, PixelError/train: 0.2418, Recall/train: 1.0000, Precision/train: 0.7582, Loss/val: 0.0738, VanillaLoss/val: 0.0738, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 9/500, Loss/train: 0.0193, RandError/train: 0.3937, PixelError/train: 0.2695, Recall/train: 1.0000, Precision/train: 0.7305, Loss/val: 0.0712, VanillaLoss/val: 0.0712, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 10/500, Loss/train: 0.0209, RandError/train: 0.3710, PixelError/train: 0.2460, Recall/train: 1.0000, Precision/train: 0.7540, Loss/val: 0.0679, VanillaLoss/val: 0.0679, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 11/500, Loss/train: 0.0154, RandError/train: 0.3778, PixelError/train: 0.2528, Recall/train: 1.0000, Precision/train: 0.7472, Loss/val: 0.0647, VanillaLoss/val: 0.0647, RandError/val: 0.3202, PixelError/val: 0.2002, Recall/val: 1.0000, Precision/val: 0.7998\n",
      "Epoch 12/500, Loss/train: 0.0172, RandError/train: 0.3762, PixelError/train: 0.2512, Recall/train: 0.9867, Precision/train: 0.7520, Loss/val: 0.0623, VanillaLoss/val: 0.0623, RandError/val: 0.3231, PixelError/val: 0.2026, Recall/val: 0.9898, Precision/val: 0.8029\n",
      "Epoch 13/500, Loss/train: 0.0175, RandError/train: 0.2787, PixelError/train: 0.1673, Recall/train: 0.9240, Precision/train: 0.8626, Loss/val: 0.0614, VanillaLoss/val: 0.0614, RandError/val: 0.3249, PixelError/val: 0.2041, Recall/val: 0.9434, Precision/val: 0.8261\n",
      "Epoch 14/500, Loss/train: 0.0157, RandError/train: 0.2856, PixelError/train: 0.1726, Recall/train: 0.8696, Precision/train: 0.8884, Loss/val: 0.0609, VanillaLoss/val: 0.0609, RandError/val: 0.3126, PixelError/val: 0.1939, Recall/val: 0.9029, Precision/val: 0.8614\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrightness_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1385\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvanilla_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m }\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrain_fixed_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/train.py:345\u001b[0m, in \u001b[0;36mtrain_fixed_hyperparams\u001b[0;34m(base_dir, local, params)\u001b[0m\n\u001b[1;32m    331\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    333\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m init_data_loaders(\n\u001b[1;32m    334\u001b[0m     batch_size,\n\u001b[1;32m    335\u001b[0m     brightness_prob,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m     val_images,\n\u001b[1;32m    344\u001b[0m )\n\u001b[0;32m--> 345\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrightness_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43melastic_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflip_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_w0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_w1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_cooldown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_save_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotate_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtranslate_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_adam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cosine_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_percent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvanilla_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/train.py:660\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(brightness_prob, dropout_p, early_stop_patience, elastic_prob, flip_prob, loss_sigma, loss_w0, loss_w1, lr, momentum, lr_cooldown, lr_factor, lr_patience, min_lr, min_save_epoch, num_epochs, rotate_prob, t_0, t_mult, train_dataloader, translate_prob, use_adam, use_cosine_scheduler, val_dataloader, val_percent, use_vanilla_loss, base_dir, local, trial)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m    659\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 660\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    662\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/train.py:65\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 65\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     enc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(enc1))\n\u001b[1;32m     67\u001b[0m     enc3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(enc2))\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Crack_Detection/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 8,\n",
    "    \"brightness_prob\": 0.1385,\n",
    "    \"dropout_p\": 0.5329,\n",
    "    \"elastic_prob\": 0.0157,\n",
    "    \"flip_prob\": 0.0427,\n",
    "    \"lr\": 0.000363,\n",
    "    \"lr_cooldown\": 1,\n",
    "    \"lr_factor\": 0.0693,\n",
    "    \"lr_patience\": 18,\n",
    "    \"min_lr\": 1.002e-08,\n",
    "    \"rotate_prob\": 0.472,\n",
    "    \"translate_prob\": 0.1538,\n",
    "    \"use_adam\": True,\n",
    "    \"use_cosine_scheduler\": False,\n",
    "    \"vanilla_loss\": True,\n",
    "}\n",
    "num_epochs = 500\n",
    "min_save_epoch = 30\n",
    "early_stop_patience = 50\n",
    "train_fixed_hyperparams(\n",
    "    base_dir, LOCAL, params, num_epochs, min_save_epoch, early_stop_patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of studies: 14\n",
      "study-0502-175709\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# study_name = \"study-0506-190624\"\n",
    "study_name = \"study-0502-175711\"\n",
    "# study_name = \"study-0428\"\n",
    "storage = f\"sqlite:///Data/{study_name}/Data/seg-study.db\"\n",
    "studies = optuna.study.get_all_study_summaries(storage=storage)\n",
    "print(\"Num of studies:\", len(studies))\n",
    "study = studies[-1]\n",
    "print(study.study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"Data/{study_name}/Data/studies/{study.study_name}.pkl\", \"rb\") as f:\n",
    "        study_dict = pickle.load(f)\n",
    "\n",
    "    study = optuna.load_study(\n",
    "        study_name=study.study_name,\n",
    "        storage=storage,\n",
    "        sampler=study_dict[\"sampler\"],\n",
    "        pruner=study_dict[\"pruner\"],\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    study = optuna.load_study(study_name=study.study_name, storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13715654611587524,\n",
       " 47,\n",
       " <optuna.pruners._median.MedianPruner at 0x7437597b1870>,\n",
       " {'flip_prob': 0.042747388239577966,\n",
       "  'rotate_prob': 0.4719902190284881,\n",
       "  'elastic_prob': 0.01567998717280196,\n",
       "  'translate_prob': 0.15377448395168106,\n",
       "  'brightness_prob': 0.138486416623626,\n",
       "  'batch_size': 8,\n",
       "  'dropout_p': 0.5328890961652364,\n",
       "  'vanilla_loss': True,\n",
       "  'use_adam': True,\n",
       "  'lr': 0.00036296166101104416,\n",
       "  'use_cosine_scheduler': False,\n",
       "  'min_lr': 1.0017766083008169e-08,\n",
       "  'lr_patience': 18,\n",
       "  'lr_cooldown': 1,\n",
       "  'lr_factor': 0.06925485872989952})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value, len(study.trials), study.pruner, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14338421821594238,\n",
       " 100,\n",
       " <optuna.pruners._hyperband.HyperbandPruner at 0x7c74eecb5390>,\n",
       " {'flip_prob': 0.04459255293028834,\n",
       "  'rotate_prob': 0.40379419104333913,\n",
       "  'elastic_prob': 0.014062767704262479,\n",
       "  'translate_prob': 0.33608821897374763,\n",
       "  'brightness_prob': 0.23828063471331679,\n",
       "  'batch_size': 9,\n",
       "  'dropout_p': 0.2887745942859943,\n",
       "  'vanilla_loss': True,\n",
       "  'use_adam': True,\n",
       "  'lr': 0.0003909349124991186,\n",
       "  'use_cosine_scheduler': False,\n",
       "  'min_lr': 6.945255506527192e-08,\n",
       "  'lr_patience': 24,\n",
       "  'lr_cooldown': 1,\n",
       "  'lr_factor': 0.2878405900553068})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value, len(study.trials), study.pruner, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in study.trials:\n",
    "    params = trial.params\n",
    "    if not params[\"vanilla_loss\"]:\n",
    "        v = trial.value\n",
    "        if v and v < 0.25:\n",
    "            print(f\"{v:0.3f}\", trial.number, trial.params, trial.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_adam': np.float64(0.3977645095745252),\n",
       " 'vanilla_loss': np.float64(0.1406793931554693),\n",
       " 'elastic_prob': np.float64(0.08746186350862907),\n",
       " 'batch_size': np.float64(0.08671901945241697),\n",
       " 'use_cosine_scheduler': np.float64(0.08402969690245228),\n",
       " 'brightness_prob': np.float64(0.06316926781526236),\n",
       " 'translate_prob': np.float64(0.043377337361138406),\n",
       " 'rotate_prob': np.float64(0.031254978146683376),\n",
       " 'flip_prob': np.float64(0.025227132797285463),\n",
       " 'min_lr': np.float64(0.021256423150298954),\n",
       " 'dropout_p': np.float64(0.0190603781358387)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image_dir, train_images, train_mask_dir, val_images, val_percent) = (\n",
    "    init_datasets(base_dir)\n",
    ")\n",
    "\n",
    "flip_prob = 0.1\n",
    "rotate_prob = 0.1\n",
    "elastic_prob = 0.11\n",
    "translate_prob = 0.1\n",
    "brightness_prob = 0.1\n",
    "batch_size = 1 if LOCAL else 9\n",
    "train_dataloader, val_dataloader = init_data_loaders(\n",
    "    batch_size,\n",
    "    brightness_prob,\n",
    "    elastic_prob,\n",
    "    flip_prob,\n",
    "    rotate_prob,\n",
    "    train_image_dir,\n",
    "    train_images,\n",
    "    train_mask_dir,\n",
    "    translate_prob,\n",
    "    val_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwsxMbNmlhdP"
   },
   "outputs": [],
   "source": [
    "for images, masks in train_dataloader:\n",
    "    image = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "    mask = masks[0].cpu().numpy().squeeze()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(image, cmap=\"gray\")\n",
    "    axs[1].imshow(mask, cmap=\"gray\")\n",
    "    assert image.shape[:2] == (572, 572)\n",
    "    assert mask.shape == (388, 388)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9lGNuk4W7KF",
    "outputId": "bde762f9-2ab3-4d59-ddd8-8d5501cff58a"
   },
   "outputs": [],
   "source": [
    "loss_w0, loss_sigma = 5, 5\n",
    "loss_w1 = 1.0\n",
    "dropout_p = 0.2\n",
    "vanilla_loss = True\n",
    "\n",
    "test_image_dir = os.path.join(base_dir, \"isbi_2012_challenge/test/imgs\")\n",
    "test_mask_dir = os.path.join(base_dir, \"isbi_2012_challenge/test/labels\")\n",
    "\n",
    "test_images = os.listdir(test_image_dir)\n",
    "test_transforms = ImageMaskTransform(train=False)\n",
    "test_dataset = SegmentationDataset(\n",
    "    test_image_dir, test_mask_dir, test_images, transform=test_transforms\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "pretrained_weights_path = \"checkpoints/C1.pth\"\n",
    "model = UNet(dropout_p=dropout_p)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "accuracy_metric_test = BinaryAccuracy().to(device)\n",
    "precision_metric_test = BinaryPrecision().to(device)\n",
    "recall_metric_test = BinaryRecall().to(device)\n",
    "rand_score_metric_test = RandScore().to(device)\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        labels = labels.squeeze(1)\n",
    "        loss = cross_entropy_weighted(\n",
    "            outputs,\n",
    "            labels,\n",
    "            device,\n",
    "            loss_w0,\n",
    "            loss_sigma,\n",
    "            loss_w1,\n",
    "            vanilla=vanilla_loss,\n",
    "        )\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        accuracy_metric_test.update(preds, labels)\n",
    "        recall_metric_test.update(preds, labels)\n",
    "        precision_metric_test.update(preds, labels)\n",
    "        rand_score_metric_test.update(preds.view(-1), labels.view(-1))\n",
    "\n",
    "print(\n",
    "    f\"(Test) Loss: {test_loss / len(test_dataloader):.4f}, \"\n",
    "    f\"Rand error: {1 - rand_score_metric_test.compute():.4f} \"\n",
    "    f\"Pixel Error: {1 - accuracy_metric_test.compute():.4f} \"\n",
    "    f\"Recall: {recall_metric_test.compute():.4f} \"\n",
    "    f\"Precision: {precision_metric_test.compute():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K52mxkXvBKP0",
    "outputId": "8e246a43-f660-4e1c-9c4d-c46504d9093c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        image = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "        mask = labels[0].cpu().numpy().squeeze()\n",
    "\n",
    "        predicted_mask = torch.argmax(outputs[0], dim=0).cpu().numpy()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        axs[0].imshow(image, cmap=\"gray\")\n",
    "        axs[0].set_title(\"Image\")\n",
    "        axs[0].axis(\"off\")\n",
    "\n",
    "        axs[1].imshow(mask, cmap=\"gray\")\n",
    "        axs[1].set_title(\"Ground Truth Mask\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "        axs[2].imshow(predicted_mask, cmap=\"gray\")\n",
    "        axs[2].set_title(\"Predicted Mask\")\n",
    "        axs[2].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "lylunDHWW7KD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "W0, SIGMA = 5, 5\n",
    "for images, labels in train_dataloader:\n",
    "    borders = find_boundaries(labels)\n",
    "    dist = distance_transform_edt(~borders)\n",
    "    w = W0 * np.exp(-2 * dist**2 / SIGMA**2)\n",
    "\n",
    "    labels_bincount = torch.bincount(labels.flatten())\n",
    "    w_class = labels_bincount.sum() / labels_bincount\n",
    "    print(w_class, labels_bincount.sum())\n",
    "\n",
    "    class_map = w_class[labels]\n",
    "    print(class_map)\n",
    "\n",
    "    w_final = class_map.numpy() + w\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(19, 6))\n",
    "    axs[0].imshow(labels.squeeze(), cmap=\"gray\")\n",
    "    axs[1].imshow(~borders.squeeze(), cmap=\"gray\")\n",
    "    axs[2].imshow(w.squeeze(), cmap=\"coolwarm\")\n",
    "    axs[3].imshow(w_final.squeeze(), cmap=\"coolwarm\")\n",
    "    plt.show()\n",
    "    plt.hist(w.flatten(), bins=10)\n",
    "    plt.show()\n",
    "    plt.hist(w_final.flatten(), bins=10)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrfX8NkNW7KF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
